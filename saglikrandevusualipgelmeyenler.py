# -*- coding: utf-8 -*-
"""SaglikRandevusuAlipGelmeyenler.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V_xrWOHwnfBfSupJSCawUeAm1LP0LmUJ

# ***Randevu Katılım Tahmini: Sağlıkta Veri Analitiği ve Makine Öğrenimi Uygulaması***

# ***VERİ SETİNİN SAYFAYA DAHİL EDİLMESİ***
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
from scipy.stats import shapiro
import statsmodels.api as sm
from scipy.stats import ttest_ind
from scipy.stats import chi2_contingency
import time
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, log_loss
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import warnings
warnings.filterwarnings("ignore")

dfC = pd.read_csv("healthcare_noshows.csv")

df = dfC.copy()

df.head(3)

df.tail(3)

"""# ***KEŞİFSEL VERİ ANALİZİ ***"""

df.shape       #satir ve sutun sayısını gösterir

df.info()

""" Sütunlar arasında PatientId, AppointmentID, Age ve Date.diff gibi sayısal veri türlerinde (float64 ve int64) sütunlar bulunurken, Gender, ScheduledDay, AppointmentDay, Neighbourhood gibi kategorik veri türlerinde (object) sütunlar da mevcuttur. Ayrıca, Scholarship gibi Boolean (True/False) türünde bir sütun da bulunmaktadır. Veri setinde boş (null) değer bulunmamaktadır. Bu veri seti, toplamda 6.2 MB bellek kullanmaktadır ve büyük bir veri seti olmasına rağmen, tekrarlanan satır bulunmamaktadır."""

df.axes

"""Bu çıktı, veri çerçevenizin yapısını göstermektedir. İlk liste, satır indekslerini belirtir ve burada RangeIndex(start=0, stop=57826, step=1) ifadesi, satır indekslerinin 0'dan başlayıp 57825'e kadar sıralandığını gösterir (toplamda 57826 satır). İkinci liste ise sütun adlarını içerir ve DataFrame'inizdeki sütunlar sırasıyla 'PatientId', 'AppointmentID', 'Gender', 'ScheduledDay', 'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension', 'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'Showed_up', 'Date.diff' olarak belirtilmiştir. Bu, veri çerçevesinin toplamda 15 sütun içerdiğini ve her bir sütunun ismini gösterir."""

df["Age"].min()

df["Age"].max()

df[df["Age"] == 115].index

df[df["Age"] == 115].head()

df.pivot_table("Age", "Gender", "Showed_up", aggfunc="mean").head()

"""Burada Showed_up False kısmı randevuya gelmeme, True kısmı ise randevuya gelme durumunu ifade eder. Cinsiyete göre pivot tablo oluşturulmuştur."""

df.describe().T

"""
Age sütunu, hastaların yaşını ifade eder. Yaşın ortalaması 38.3 yıl olup, standart sapma 22.5'tir. Yaş aralığı 1 ile 115 yıl arasında değişmektedir. Minimum yaş değeri olan 1 yaş, yaş aralığının başlangıcındaki çok küçük bir değeri işaret edebilir, ancak veri setinde doğrudan hatalı veya olağan dışı yaşlar olmadığını gösteriyor. Yaşın genel olarak dağılımı düzgün görünüyor.

Date.diff sütunu, randevu tarihi ile randevu için belirlenen tarih arasındaki farkı (gün cinsinden) ifade eder. Bu sütunun ortalama değeri 10.17 gün olup, standart sapma 15.26'dır. Minimum değer -6 olarak gözükse de, bu durum genellikle hata veya veri giriş hatası olabilir (örneğin, geçmiş tarihlerde yapılan randevuların güncellenmesi). Maksimum değer 179 gün ile, bazı randevuların oldukça uzun süre önce planlandığını gösteriyor."""

df.groupby("Gender")["Showed_up"].describe().T

"""Burada cinsiyete göre temel istatistiksel bilgiler oluşturulmuştur; count kısmında kadınların toplam sayısı ve erkeklerin toplam sayısı ifade edilmiş, unique kısmında benzersiz değer sayısı gösterilmiş, Top kısmında en yaygın değerleri verilmiş yani burada kadınların ve erkeklerin büyük çoğunluğunun rendevularına geldikleri gösteriliyor, freq kısmında ise en yaygın değerin görülme sayısı verilmiştir."""

df.duplicated().sum()

"""Burada duplicated ifadesi benzersiz değerleri göstermektedir. Burada 0 değerinin olması veri seti içinde hiçbir tekrarlanan değerin olmadığını söyler. Yani, her satır benzersizdir ve veri setinizdeki tüm satırlar farklıdır."""

df.isnull().sum()

"""Burada isnull().sum() ile hiçbir boş değerin olmadığını ifade eder."""

diabetes =  pd.crosstab(df['Showed_up'], df['Diabetes'], margins=True)
hipertension = pd.crosstab(df['Showed_up'], df['Hipertension'], margins=True)
alchol = pd.crosstab(df['Showed_up'], df['Alcoholism'], margins=True)
handcap = pd.crosstab(df['Showed_up'], df['Handcap'], margins=True)

print(diabetes, "\n","\n", hipertension, "\n", "\n", alchol, "\n", "\n", handcap)

"""1. Diabetes (Diyabet):
Bu tablo, Diabetes (Diyabet) durumu ile randevuya gelme durumunun ilişkisini göstermektedir. False değeri, kişilerin diyabeti olmadığını, True değeri ise kişilerin diyabet hastası olduğunu belirtir. Randevuya gelmeyenler (Showed_up: False), diyabeti olmayan 20,250 kişiden ve diyabeti olan 1,430 kişiden oluşuyor, toplamda 21,680 kişi randevuya gelmemiştir. Randevuya gelenler (Showed_up: True) ise diyabeti olmayan 78,794 kişiden ve diyabeti olan 6,513 kişiden oluşuyor, toplamda 85,307 kişi randevuya gelmiştir. Son olarak, tüm veri kümesi üzerinden All sütunu, diyabeti olmayan 99,044 kişi ve diyabeti olan 7,943 kişiyi kapsayarak toplamda 106,987 bireyden bahsetmektedir.

2. Hipertension (Hipertansiyon):
Hipertansiyon durumu ile randevuya gelme arasındaki ilişkiyi gösteren tabloda, hipertansiyonu olmayan (False) ve hipertansiyonu olan (True) kişilerin sayıları verilmiştir. Randevuya gelmeyenler (Showed_up: False), hipertansiyonu olmayan 17,908 kişi ve hipertansiyonu olan 3,772 kişiden oluşarak toplamda 21,680 kişiyi oluşturuyor. Randevuya gelenler (Showed_up: True) ise hipertansiyonu olmayan 67,278 kişi ve hipertansiyonu olan 18,029 kişiden oluşuyor, bu da toplamda 85,307 kişiyi temsil ediyor. All sütununda ise tüm veri kümesindeki hipertansiyonu olmayan 85,186 kişi ve hipertansiyonu olan 21,801 kişi yer alıyor, toplamda 106,987 kişi var.

3. Alcoholism (Alkol Bağımlılığı):
Bu tablo, alkol bağımlılığı durumu ile randevuya gelme ilişkisini gösteriyor. False değeri, kişilerin alkol bağımlılığı olmadığını, True değeri ise kişilerin alkol bağımlılığı olduğunu ifade eder. Randevuya gelmeyenler (Showed_up: False), alkol bağımlılığı olmayan 21,003 kişi ve alkol bağımlılığı olan 677 kişiden oluşuyor, toplamda 21,680 kişi randevuya gelmemiştir. Randevuya gelenler (Showed_up: True) ise alkol bağımlılığı olmayan 82,624 kişi ve alkol bağımlılığı olan 2,683 kişiden oluşuyor, toplamda 85,307 kişi randevuya gelmiştir. All sütununda, alkol bağımlılığı olmayan 103,627 kişi ve alkol bağımlılığı olan 3,360 kişi yer alıyor, toplamda 106,987 kişiyi kapsamaktadır.

4. Handcap (Engellilik Durumu):
Handcap (Engellilik durumu) ile randevuya gelme arasındaki ilişkiyi gösteren tabloda, engelli olmayan (False) ve engelli (True) kişilerin sayıları verilmiştir. Randevuya gelmeyenler (Showed_up: False), engelli olmayan 21,273 kişi ve engelli 407 kişiden oluşuyor, toplamda 21,680 kişi randevuya gelmemiştir. Randevuya gelenler (Showed_up: True) ise engelli olmayan 83,474 kişi ve engelli 1,833 kişiden oluşuyor, bu da toplamda 85,307 kişiyi oluşturuyor. All sütununda engelli olmayan 104,747 kişi ve engelli 2,240 kişi yer almakta, toplamda 106,987 kişi bulunmaktadır.
"""

plt.figure(figsize=(17,6))
plt.subplot(2, 2, 1)


plt.pie(
    [diabetes.loc[True, True], diabetes.loc[False, True]],
    labels=['Randevuya Katıldı', 'Randevuya Katılmadı'],
    autopct='%1.1f%%',
    startangle=90,
    colors=['#4CAF50', '#FF6347']
)
plt.title("Diyabeti Olanların Randevu Katılımı")

plt.subplot(2, 2, 2)
plt.pie(
    [hipertension.loc[True, True], hipertension.loc[False, True]],
    labels=['Randevuya Katıldı', 'Randevuya Katılmadı'],
    autopct='%1.1f%%',
    startangle=90,
    colors=['#6495ED', '#FF6347']
)
plt.title("Hipertansiyonu Olanların Randevu Katılımı")

plt.subplot(2, 2, 3)
plt.pie(
    [alchol.loc[True, True], alchol.loc[False, True]],
    labels=['Randevuya Katıldı', 'Randevuya Katılmadı'],
    autopct='%1.1f%%',
    startangle=90,
    colors=['#FFD700', '#FF6347']
)
plt.title("Alkol Sorunu Olanların Randevu Katılımı")

plt.subplot(2, 2, 4)
plt.pie(
    [handcap.loc[True, True], handcap.loc[False, True]],
    labels=['Randevuya Katıldı', 'Randevuya Katılmadı'],
    autopct='%1.1f%%',
    startangle=90,
    colors=['#898121', '#FF6347']
)
plt.title("Engel Durumu Olanların Randevu Katılımı")

plt.tight_layout()
plt.show()

sms_data = df.groupby("Showed_up").agg({"SMS_received": "sum"})

plt.figure(figsize=(17,6))
sms_data.plot(kind='bar', legend=False, color=['#4CAF50', '#FF6347'])
plt.title("Randevu Katılım Durumuna Göre Alınan SMS Sayısı")
plt.xlabel("Randevu Katılım Durumu")
plt.ylabel("Toplam SMS Sayısı")
plt.xticks(ticks=[0, 1], labels=["Katılmadı", "Katıldı"], rotation=20)

plt.show()

neighbourhood_data = df.groupby("Neighbourhood").agg({"Showed_up": "sum"}).sort_values(by="Showed_up", ascending=False)

top_neighbourhoods = neighbourhood_data.head(10)

plt.figure(figsize=(12, 8))
top_neighbourhoods.plot(kind='bar', legend=False, color='#4CAF50')

plt.title("En Yüksek Randevu Katılımına Sahip İlk 10 Mahalle")
plt.xlabel("Mahalle")
plt.ylabel("Toplam Randevu Katılım Sayısı")
plt.xticks(rotation=45)

plt.show()

neighbourhood_data = df.groupby("Neighbourhood").agg({"Showed_up": "sum"})

bottom_neighbourhoods = neighbourhood_data.nsmallest(10, "Showed_up")

plt.figure(figsize=(12, 8))
bottom_neighbourhoods.plot(kind='bar', legend=False, color='#FF6347')

plt.title("En Düşük Randevu Katılımına Sahip İlk 10 Mahalle")
plt.xlabel("Mahalle")
plt.ylabel("Toplam Randevu Katılım Sayısı")
plt.xticks(rotation=45)

plt.ylim(0, bottom_neighbourhoods['Showed_up'].max() + 5)

plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(df['Age'], bins=30, kde=True, color = "#FC8D62")
plt.title('Yaş Dağılımı')
plt.xlabel('Yaş')
plt.ylabel('Sayı')
plt.tight_layout()
plt.show()

df['Age_Group'] = pd.cut(df['Age'], bins=[0, 18, 35, 60, 100], labels=['Genç', 'Yetişkin', 'Orta Yaş', 'Yaşlı'])

plt.figure(figsize=(10,6))
sns.countplot(x='Age_Group', data=df, palette='Set2')
plt.xlabel('Yaş Grubu')
plt.ylabel('Count')
plt.show()

"""# ***HİPOTEZ TESTLERİ***

1. Randevuya gelip gelmeme ile yaş arasındaki ilişki;

*   Hipotez: Yaş değişkeni ile randevu durumu arasında bir ilişki durumu.
*   H0: Yaş değişkeni ile randevu durumu arasında anlamlı bir ilişki yoktur.

*   H1: Yaş değişkeni ile randevu durumu arasında anlamlı bir ilişki vardır.
*   Test: T-testi (Shapiro-Wilk) / Mann-Whitney U Testi
"""

age_showed_up = df[df['Showed_up'] == True]['Age']
age_no_show = df[df['Showed_up'] == False]['Age']

print("age_showed_up length:", len(age_showed_up))
print("age_no_show length:", len(age_no_show))

stat_showed, p_showed = shapiro(age_showed_up)
stat_no_show, p_no_show = shapiro(age_no_show)

print(f"Shapiro-Wilk Testi (Showed Up): Test Statistic = {stat_showed}, p-value = {p_showed}")
print(f"Shapiro-Wilk Testi (No Show): Test Statistic = {stat_no_show}, p-value = {p_no_show}")

"""Shapiro-Wilk testi sonuçlarına göre, hem randevuya gelenlerin hem de gelmeyenlerin yaş verileri normal dağılıma uygun değildir (p-value < 0.05).
Bu nedenle, normal dağılım varsayımına dayalı yöntemler yerine non-parametrik testler kullanılmalıdır.


"""

from scipy.stats import mannwhitneyu

# Perform Mann-Whitney U Test
stat_u, p_u = mannwhitneyu(age_showed_up, age_no_show)

# Display the results
print(f"Mann-Whitney U Test: Test Statistic = {stat_u}, p-value = {p_u}")

"""Mann-Whitney U testi sonuçlarına göre, randevuya gelenler ve gelmeyenler arasındaki yaşlar arasında anlamlı bir fark bulunmaktadır (p-value < 0.05).
Test istatistiği (U = 1,015,591,109) oldukça yüksek bir değere sahip, bu da gruplar arasındaki farkın büyük olduğunu gösteriyor.
Bu sonuç, randevuya gelme durumu ile yaşlar arasında istatistiksel olarak anlamlı bir ilişki olduğunu ortaya koymaktadır.
H0 hipotezi reddedilmiştir.

2. Cinsiyet ile randevu durumu arasındaki ilişki;

*   Hipotez: Cinsiyet ile randevuya gelip gelmeme arasındaki ilişki.
*   H0: Hastanın cinsiyeti ile randevu durumu arasında anlamlı bir ilişki yoktur.

*   H1: Hastanın cinyiset durumu ile randevuya gelme yada gelmeme arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi
"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['Gender'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Cinsiyet ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Cinsiyet ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""3. Mahalle ile randevu durumu arasındaki ilişki;

*   Hipotez: Randevuya gelip gelmeme durumu ile mahalle bilgisi arasındaki ilişki.
*   H0: Hastanın randevu durumu ile mahalle bilgisi arasında anlamlı bir ilişki yoktur.

*   H1: Hastanın randevu durumu ile mahalle bilgisi arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi




"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['Neighbourhood'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Mahalle bilgisi ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Mahalle bilgisi ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""4. Hipertansiyon ile randevu durumu arasındaki ilişki;

*   Hipotez: Hastanın hipertansiyon olması ile randevu durumu ilişkisi.
*   H0: Hastanın randevuya gelip gelmeme durumu ile hipertansiyon hastası olma arasında anlamlı bir ilişki yoktur.

*   H1: Hastanın randevuya gelip gelmeme durumu ile hipertansiyon hastası olma arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi




"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['Hipertension'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Hipertansiyon ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Hipertansiyon ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""5. Diyabet ile randevu durumu arasındaki ilişki;

*   Hipotez: Hastanın diyabet olması ile randevu durumu ilişkisi.
*   H0: Hastanın randevuya gelip gelmeme durumu ile diyabet hastası olma arasında anlamlı bir ilişki yoktur.

*   H1: Hastanın randevuya gelip gelmeme durumu ile diyabet hastası olma arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi





"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['Diabetes'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Diyabet ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Diyabet ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""6. Alkol Bağımlılığı ile randevu durumu arasındaki ilişki;

*   Hipotez: Hastanın alkol bağımlısı olması ile randevu durumu ilişkisi.
*   H0: Hastanın randevuya gelip gelmeme durumu ile alkol bağımlısı olma arasında anlamlı bir ilişki yoktur.

*   H1: Hastanın randevuya gelip gelmeme durumu ile alkol bağımlısı olma arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi / Logistik Regresyon




"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['Alcoholism'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Alkol bağımlılığı ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Alkol bağımlılığı ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

df = df.dropna(subset=['Alcoholism'])
df['Alcoholism'] = df['Alcoholism'].astype(int)
df['Showed_up'] = df['Showed_up'].astype(int)

X = df[['Alcoholism']]
X = sm.add_constant(X)
y = df['Showed_up']

model = sm.Logit(y, X)
result = model.fit()

print(result.summary())

p_value = result.pvalues['Alcoholism']
if p_value < 0.05:
    print("H0 hipotezi reddedilir: Alkol bağımlılığı ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Alkol bağımlılığı ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""7. Engel durumu ile randevu gelip gelmeme ilişkisi;

*   Hipotez: Hastanın engel durumunun bulunması ile randevuya gelip gelmeme arasındaki ilişki.
*   H0: Hastanın engel durumu ile randevuya gelip gelmeme arasında anlamlı bir ilişki yoktur.

*   H1: Hastanın engel durumu ile randevuya gelip gelmeme arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi




"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['Handcap'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Hastanın engel durumu ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Hastanın engel durumu ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""8. Hastanın sağlık yardımı alması ile randevu durumu arasındaki ilişki;

*   Hipotez: Hastanın randevu durumu ile sağlık yardımı ilişkisi.
*   H0: Hastanın sağlık yardımı alması ile randevuya gelip gelmemesi arasında anlamlı bir ilişki yoktur.

*   H1: Hastının sağlık yardımı alması ile randevuya gelip gelmemesi arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi




"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['Scholarship'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Hastanın sağlık bursu alması durumu ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Hastanın sağlık bursu alması durumu ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""9. SMS hatırlatması ile randevu durumu arasındaki ilişki;

*   Hipotez: Hastaya randevu öncesinde gelen SMS hatırlatması ile randevuya gelip gelmeme arasındaki ilişki.
*   H1: Hastaya gelen SMS hatırlatması ile randevu durumu arasında anlamlı bir ilişki yoktur.

*   H1: Hastaya gelen SMS hatırlatması ile randevu durumu arasında anlamlı bir ilişki vardır.
*   Test: Ki-Kare Testi




"""

# Frekans tablosu oluşturma
contingency_table = pd.crosstab(df['SMS_received'], df['Showed_up'])

# Ki-Kare testi
chi2, p, dof, expected = chi2_contingency(contingency_table)

print(f"Ki-Kare Değeri: {chi2}")
print(f"P-değeri: {p}")
print(f"Serbestlik Derecesi: {dof}")
print(f"Beklenen Değerler Tablosu: \n{expected}")

if p < 0.05:
    print("H0 hipotezi reddedilir: Hastanın SMS alması durumu ile randevuya gelme durumu arasında anlamlı bir ilişki vardır.")
else:
    print("H0 hipotezi kabul edilir: Hastanın SMS alması durumu ile randevuya gelme durumu arasında anlamlı bir ilişki yoktur.")

"""10. Hastanın randevu aldığı gün ile randevu günü arasındaki farkın randevu durumu ile ilişkisi;

*   Hipotez: Hastanın hastane randevusu aldığı gün ile hastaneye gideceği gün arasındaki fark ile randevuya gelip gelmeme durumu üzerindeki ilişki.
*   H0: Hastanın randevu aldığı gün ile randevu günü arasındaki farkın randevu durumu üzerinde bir etkisi yoktur.

*   H1: Hastanın randevu aldığı gün ile randevu günü arasındaki farkın randevu durumu ile anlamlı bir ilişkisi vardır.
*   Test: T-Testi




"""

df['Date.diff'] = pd.to_numeric(df['Date.diff'], errors='coerce')

group_1 = df[df['Showed_up'] == 1]['Date.diff']
group_2 = df[df['Showed_up'] == 0]['Date.diff']

stat, p_value = ttest_ind(group_1, group_2)

print("T-Testi Sonucu:")
print(f"Test istatistiği: {stat}")
print(f"P-değeri: {p_value}")

alpha = 0.05
if p_value < alpha:
    print("H0 reddedildi: Hastanın randevu aldığı gün ile randevu günü arasındaki fark, randevuya gidip gitmeme durumuyla anlamlı bir ilişkiye sahiptir.")
else:
    print("H0 kabul edildi: Hastanın randevu aldığı gün ile randevu günü arasındaki fark, randevuya gidip gitmeme durumu üzerinde anlamlı bir etkiye sahip değildir.")

"""# ***MODEL KURMAK İÇİN VERİ HAZIRLAMA***"""

df.drop(["PatientId", "AppointmentID"], axis=1, inplace=True)

df["Gender"] = df["Gender"].map({"F": 0, "M": 1})

df["ScheduledDay"] = pd.to_datetime(df["ScheduledDay"])
df["AppointmentDay"] = pd.to_datetime(df["AppointmentDay"])

df["DaysUntilAppointment"] = (df["AppointmentDay"] - df["ScheduledDay"]).dt.days

df["Neighbourhood"] = df["Neighbourhood"].astype("category").cat.codes

boolean_columns = ["Scholarship", "Hipertension", "Diabetes", "Alcoholism", "Handcap", "SMS_received", "Showed_up"]
df[boolean_columns] = df[boolean_columns].astype(int)

df.drop(["ScheduledDay", "AppointmentDay"], axis=1, inplace=True)

y = df[["Showed_up"]]
x = df.drop(['Showed_up'], axis = 1)

x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.70, random_state=42)

standart = StandardScaler()

x_train_scaler = standart.fit_transform(x_train)
x_test_scaler = standart.transform(x_test)

df.head(1)

"""# ***MODEL KURULMASI***"""

param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'solver': ['lbfgs', 'liblinear'],
    'max_iter': [100, 200, 300]
}
                                                                                    #Logistic Regression
start_train_time = time.time()
lr = LogisticRegression()
grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)
grid_search.fit(x_train_scaler, y_train)
end_train_time = time.time()

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_
total_train_time1 = end_train_time - start_train_time


y_train_pred = best_model.predict(x_train_scaler)

train_accuracy1 = accuracy_score(y_train, y_train_pred)
train_f1_1 = f1_score(y_train, y_train_pred)
train_recall1 = recall_score(y_train, y_train_pred)
train_precision1 = precision_score(y_train, y_train_pred)
train_confusion1 = confusion_matrix(y_train, y_train_pred)
train_roc_auc1 = roc_auc_score(y_train, y_train_pred)
train_log_loss1 = log_loss(y_train, y_train_pred)





start_test_time = time.time()
y_test_pred = best_model.predict(x_test_scaler)
end_test_time = time.time()
total_test_time1 = end_test_time - start_test_time

test_accuracy1 = accuracy_score(y_test, y_test_pred)
test_f1_1 = f1_score(y_test, y_test_pred)
test_recall1 = recall_score(y_test, y_test_pred)
test_precision1 = precision_score(y_test, y_test_pred)
test_confusion1 = confusion_matrix(y_test, y_test_pred)
test_roc_auc1 = roc_auc_score(y_test, y_test_pred)
test_log_loss1 = log_loss(y_test, y_test_pred)




print(f"Best Parameters: {best_params}")
print(f"Train Time : {total_train_time1}")
print(f"Train Accuracy : {train_accuracy1}")
print(f"Train F1 : {train_f1_1}")
print(f"Train Recall : {train_recall1}")
print(f"Train Precision : {train_precision1}")
print(f"Train Confusion Matrix : {train_confusion1}")
print(f"Train Roc Auc : {train_roc_auc1}")
print(f"Train Log Loss : {train_log_loss1}")
print("------------------------------------------------------")
print(f"Test Time : {total_test_time1}")
print(f"Test Accuracy: {test_accuracy1}")
print(f"Test F1 : {test_f1_1}")
print(f"Test Recall : {test_recall1}")
print(f"Test Precision : {test_precision1}")
print(f"Test Confusion Matrix : {test_confusion1}")
print(f"Test Roc Auc : {test_roc_auc1}")
print(f"Test Log Loss : {test_log_loss1}")

param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt', 'log2'],
    'class_weight': ['balanced'],
    'ccp_alpha': [0.0, 0.01, 0.1]
}                                                                                   #Decision Tree Classifier

start_train_time = time.time()
dc = DecisionTreeClassifier()
grid_search = GridSearchCV(estimator= dc, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)
grid_search.fit(x_train_scaler, y_train)
end_train_time = time.time()

best_model2 = grid_search.best_estimator_
best_params2 = grid_search.best_params_
total_train_time2 = end_train_time - start_train_time

y_tarin_pred = best_model2.predict(x_train_scaler)

train_accuracy2 = accuracy_score(y_train, y_train_pred)
train_f1_2 = f1_score(y_train, y_train_pred)
train_recall2 = recall_score(y_train, y_train_pred)
train_precision2 = precision_score(y_train, y_train_pred)
train_confusion2 = confusion_matrix(y_train, y_train_pred)
train_roc_auc2 = roc_auc_score(y_train, y_train_pred)
train_log_loss2 = log_loss(y_train, y_train_pred)



start_test_time = time.time()
y_test_pred = best_model2.predict(x_test_scaler)
end_test_time = time.time()
total_test_time2 = end_test_time - start_test_time

test_accuracy2 = accuracy_score(y_test, y_test_pred)
test_f1_2 = f1_score(y_test, y_test_pred)
test_recall2 = recall_score(y_test, y_test_pred)
test_precision2 = precision_score(y_test, y_test_pred)
test_confusion2 = confusion_matrix(y_test, y_test_pred)
test_roc_auc2 = roc_auc_score(y_test, y_test_pred)
test_log_loss2 = log_loss(y_test, y_test_pred)




print(f"Best Parameters: {best_params2}")
print(f"Train Time : {total_train_time2}")
print(f"Train Accuracy : {train_accuracy2}")
print(f"Train F1 : {train_f1_2}")
print(f"Train Recall : {train_recall2}")
print(f"Train Precision : {train_precision2}")
print(f"Train Confusion Matrix : {train_confusion2}")
print(f"Train Roc Auc : {train_roc_auc2}")
print(f"Train Log Loss : {train_log_loss2}")
print("------------------------------------------------------")
print(f"Test Time : {total_test_time2}")
print(f"Test Accuracy: {test_accuracy2}")
print(f"Test F1 : {test_f1_2}")
print(f"Test Recall : {test_recall2}")
print(f"Test Precision : {test_precision2}")
print(f"Test Confusion Matrix : {test_confusion2}")
print(f"Test Roc Auc : {test_roc_auc2}")
print(f"Test Log Loss : {test_log_loss2}")

param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['auto', 'sqrt'],
    'bootstrap': [True],
    'criterion': ['gini'],
}                                                                                   #Random Forest Classifier

start_train_time = time.time()
rd = RandomForestClassifier()
grid_search = GridSearchCV(estimator= rd, param_grid= param_grid, scoring='accuracy', cv=5, n_jobs=-1, verbose=1)
grid_search.fit(x_train_scaler, y_train)
end_train_time = time.time()

best_model3 = grid_search.best_estimator_
best_params3 = grid_search.best_params_
total_train_time3 = end_train_time - start_train_time

y_train_pred = best_model3.predict(x_train_scaler)

train_accuracy3 = accuracy_score(y_train, y_train_pred)
train_f1_3 = f1_score(y_train, y_train_pred)
train_recall3 = recall_score(y_train, y_train_pred)
train_precision3 = precision_score(y_train, y_train_pred)
train_confusion3 = confusion_matrix(y_train, y_train_pred)
train_roc_auc3 = roc_auc_score(y_train, y_train_pred)
train_log_loss3 = log_loss(y_train, y_train_pred)


start_test_time = time.time()
y_test_pred = best_model3.predict(x_test_scaler)
end_test_time = time.time()
total_test_time3 = end_test_time - start_test_time

test_accuracy3 = accuracy_score(y_test, y_test_pred)
test_f1_3 = f1_score(y_test, y_test_pred)
test_recall3 = recall_score(y_test, y_test_pred)
test_precision3 = precision_score(y_test, y_test_pred)
test_confusion3 = confusion_matrix(y_test, y_test_pred)
test_roc_auc3 = roc_auc_score(y_test, y_test_pred)
test_log_loss3 = log_loss(y_test, y_test_pred)




print(f"Best Parameters: {best_params3}")
print(f"Train Time : {total_train_time3}")
print(f"Train Accuracy : {train_accuracy3}")
print(f"Train F1 : {train_f1_3}")
print(f"Train Recall : {train_recall3}")
print(f"Train Precision : {train_precision3}")
print(f"Train Confusion Matrix : {train_confusion3}")
print(f"Train Roc Auc : {train_roc_auc3}")
print(f"Train Log Loss : {train_log_loss3}")
print("------------------------------------------------------")
print(f"Test Time : {total_test_time3}")
print(f"Test Accuracy: {test_accuracy3}")
print(f"Test F1 : {test_f1_3}")
print(f"Test Recall : {test_recall3}")
print(f"Test Precision : {test_precision3}")
print(f"Test Confusion Matrix : {test_confusion3}")
print(f"Test Roc Auc : {test_roc_auc3}")
print(f"Test Log Loss : {test_log_loss3}")

import matplotlib.ticker as mtick
models = ['Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier']
training_times = [total_train_time1, total_train_time2, total_train_time3]
f1_score = [train_f1_1, train_f1_2, train_f1_3]

sorted_indices = np.argsort(f1_score)[::-1]
models = [models[i] for i in sorted_indices]
training_times = [training_times[i] for i in sorted_indices]
f1_score = [f1_score[i] for i in sorted_indices]

fig, ax1 = plt.subplots(figsize=(17, 6))

ax1.bar(models, training_times, color='skyblue')
ax1.set_xlabel('Modeller', color = 'blue')
ax1.set_ylabel('Eğitim Süresi (Saniye)', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')

ax2 = ax1.twinx()

ax2.plot(models, f1_score, color='red', marker='o', label='Diğer Modeller', markerfacecolor='red')

linear_index = models.index('Random Forest Classifier')
ax2.plot(models[linear_index], f1_score[linear_index], color='red', marker='*', markersize=12, label='Linear Model')

ax2.set_ylabel('f1_score', color='red')
ax2.tick_params(axis='y', labelcolor='red')

ax2.yaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f'{x:.3f}'))

plt.show()

models = ['Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier']
testing_times = [total_train_time1, total_train_time2, total_train_time3]
f1_score = [test_f1_1, test_f1_2, test_f1_3]

sorted_indices = np.argsort(f1_score)[::-1]
models = [models[i] for i in sorted_indices]
training_times = [training_times[i] for i in sorted_indices]
f1_score = [f1_score[i] for i in sorted_indices]

fig, ax1 = plt.subplots(figsize=(17, 6))

ax1.bar(models, testing_times, color='lightgreen')
ax1.set_xlabel('Modeller', color= 'green')
ax1.set_ylabel('Test Süresi (Saniye)', color='green')
ax1.tick_params(axis='y', labelcolor='green')

ax2 = ax1.twinx()

ax2.plot(models, f1_score, color='red', marker='o', label='Diğer Modeller', markerfacecolor='red')

linear_index = models.index('Random Forest Classifier')
ax2.plot(models[linear_index], f1_score[linear_index], color='red', marker='*', markersize=12, label='Linear Model')

ax2.set_ylabel('f1_score', color='red')
ax2.tick_params(axis='y', labelcolor='red')

ax2.yaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f'{x:.3f}'))

plt.show()